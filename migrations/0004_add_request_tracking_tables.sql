-- Migration: 0004_add_request_tracking_tables.sql
-- Description: Add tables for detailed scrape request and step tracking, plus asset storage.

-- Tracks overall scrape requests (on-demand or app-based)
CREATE TABLE IF NOT EXISTS scrape_requests (
    id TEXT PRIMARY KEY, -- Use the UUID generated by the worker (request_id)
    app_id TEXT REFERENCES scrape_apps(id) ON DELETE SET NULL, -- Link to app if run via app
    app_run_config TEXT, -- JSON storing overrides used for an app run (sites included/excluded, etc.)
    on_demand_url TEXT, -- URL if run on-demand
    on_demand_prompt TEXT, -- Prompt if run on-demand
    on_demand_schema_json TEXT, -- Schema used if run on-demand
    status TEXT NOT NULL DEFAULT 'queued' CHECK(status IN ('queued', 'running', 'completed', 'failed', 'terminated')),
    outcome TEXT CHECK(outcome IN ('success', 'partial_success', 'failure', 'terminated')), -- Final outcome
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL
);

-- Expands on agentic_observations to store detailed step info
-- Note: You might keep agentic_observations for the AI's direct logs and use this for structured steps.
-- Or, you could potentially merge/replace agentic_observations with this structure.
CREATE TABLE IF NOT EXISTS request_steps (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    request_id TEXT NOT NULL REFERENCES scrape_requests(id) ON DELETE CASCADE,
    step_index INTEGER NOT NULL, -- Order of the step within the request
    site_id TEXT REFERENCES app_sites(id) ON DELETE SET NULL, -- Link to site if applicable
    url TEXT, -- URL at the time of the step
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL,
    agent_goal TEXT, -- Goal for this specific step/phase
    agent_thoughts TEXT, -- Agent's reasoning/analysis
    agent_action_type TEXT, -- (e.g., navigate, click, type, wait, judge, extract, analyze_screenshot, deeper_analysis)
    agent_action_details TEXT, -- JSON containing selector, text, target URL etc.
    expected_outcome TEXT,
    actual_outcome TEXT NOT NULL CHECK(actual_outcome IN ('success', 'failure', 'pending')),
    outcome_reason TEXT, -- Explanation if failure
    UNIQUE(request_id, step_index)
);

-- Stores references to assets captured during each step
CREATE TABLE IF NOT EXISTS step_assets (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    step_id INTEGER NOT NULL REFERENCES request_steps(id) ON DELETE CASCADE,
    asset_type TEXT NOT NULL CHECK(asset_type IN ('screenshot', 'html', 'text_content', 'css', 'js_console')),
    storage_type TEXT NOT NULL DEFAULT 'r2' CHECK(storage_type IN ('r2', 'd1_blob', 'inline')), -- How/where asset is stored
    storage_ref TEXT NOT NULL, -- e.g., R2 object key, D1 row ID, or potentially inline data for small logs
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL
);

-- Stores the final extracted data for a request
CREATE TABLE IF NOT EXISTS extracted_data (
    request_id TEXT PRIMARY KEY REFERENCES scrape_requests(id) ON DELETE CASCADE,
    schema_json TEXT NOT NULL, -- The JSON schema used for the final extraction
    data TEXT NOT NULL, -- The extracted data as a JSON string
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP NOT NULL
);

-- Add indices
CREATE INDEX IF NOT EXISTS idx_scrape_requests_app_id ON scrape_requests (app_id);
CREATE INDEX IF NOT EXISTS idx_scrape_requests_status ON scrape_requests (status);
CREATE INDEX IF NOT EXISTS idx_request_steps_request_id ON request_steps (request_id);
CREATE INDEX IF NOT EXISTS idx_step_assets_step_id ON step_assets (step_id);
CREATE INDEX IF NOT EXISTS idx_step_assets_asset_type ON step_assets (asset_type);

-- Optional: Modify existing tables if needed
-- ALTER TABLE agentic_observations ADD COLUMN step_id INTEGER REFERENCES request_steps(id);
-- ALTER TABLE scraper_logs ADD COLUMN step_id INTEGER REFERENCES request_steps(id);
